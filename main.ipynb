{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "DIGITS = [\"0\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup_by_url(url):\n",
    "  result = requests.get(url)\n",
    "  html_file = result.text \n",
    "  return BeautifulSoup(html_file, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_text(url):\n",
    "  soup = get_soup_by_url(url)\n",
    "  text = soup.get_text()\n",
    "  text = text.replace(\"\\n\", \"\")\n",
    "  text = text.replace('\"', \"\")\n",
    "  text = text.translate ({ord(c): \" \" for c in \"!@#$%^&*()[]{};:,./<>?\\|`~-=_+'\\Â©\"\"\"})\n",
    "  new_text = text\n",
    "  # for i in range(len(text)-1):\n",
    "  #   if text[i].islower() and text[i+1].isupper():\n",
    "  #     # new_text = new_text + text[i] + \" \"\n",
    "  #     new_text = \"\".join([new_text, text[i], \" \"])\n",
    "  #   else:\n",
    "  #     # new_text = new_text + text[i]\n",
    "  #     new_text = \"\".join([new_text, text[i]])\n",
    "\n",
    "  new_text = new_text.replace(\"  \", \" \")   \n",
    "  new_text = new_text.lower()\n",
    "  return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### ADD REMOVE NUMBERS\n",
    "def add_plain_text_to_counts(text, words, counts):\n",
    "  new_words = words\n",
    "  new_counts = counts\n",
    "  text_to_count = text.split()\n",
    "\n",
    "  for word in text_to_count:\n",
    "    if len(word) == 1 or any(x in word for x in DIGITS):\n",
    "      continue\n",
    "    if word not in words:\n",
    "      new_words.append(word)\n",
    "      new_counts.append(1)\n",
    "    else:\n",
    "      index = new_words.index(word)\n",
    "      new_counts[index] += 1\n",
    "\n",
    "  return new_words, new_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(words, counts):\n",
    "  df = pd.DataFrame(data={\"counts\": counts, \"words\": words})\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_books = 20\n",
    "urls = []\n",
    "for i in range(num_books):\n",
    "  urls.append(f\"https://www.gutenberg.org/cache/epub/{i+50}/pg{i+50}.txt\")\n",
    "\n",
    "# urls = [\"https://en.wikipedia.org/wiki/programming\",\n",
    "#              \"https://en.wikipedia.org/wiki/words\",\n",
    "#              \"https://en.wikipedia.org/wiki/history\",\n",
    "#              \"https://en.wikipedia.org/wiki/elephant\",\n",
    "#              \"https://en.wikipedia.org/wiki/giraffe\",\n",
    "#              \"https://en.wikipedia.org/wiki/train\",\n",
    "#              \"https://en.wikipedia.org/wiki/airplane\",\n",
    "#              \"https://en.wikipedia.org/wiki/school\",\n",
    "#              \"https://en.wikipedia.org/wiki/highschool\",\n",
    "#              \"https://en.wikipedia.org/wiki/midschool\",\n",
    "#              \"https://en.wikipedia.org/wiki/Human_history\",\n",
    "#              \"https://en.wikipedia.org/wiki/war\",\n",
    "#              \"https://en.wikipedia.org/wiki/europe\",\n",
    "#              \"https://en.wikipedia.org/wiki/glasgow\",\n",
    "#              \"https://en.wikipedia.org/wiki/washington\",\n",
    "#              \"https://en.wikipedia.org/wiki/manhattan\",\n",
    "#              \"https://en.wikipedia.org/wiki/flag\",\n",
    "#              \"https://en.wikipedia.org/wiki/nation\",\n",
    "#              \"https://en.wikipedia.org/wiki/sport\",\n",
    "#              \"https://en.wikipedia.org/wiki/world\",\n",
    "#              \"https://en.wikipedia.org/wiki/statue_of_liberty\",\n",
    "#              \"https://en.wikipedia.org/wiki/boeing\",\n",
    "#              \"https://en.wikipedia.org/wiki/reading\",\n",
    "#              \"https://en.wikipedia.org/wiki/life\",\n",
    "#              \"https://en.wikipedia.org/wiki/Dubai\",\n",
    "#              \"https://en.wikipedia.org/wiki/car\",\n",
    "#              \"https://en.wikipedia.org/wiki/biology\",\n",
    "#              \"https://en.wikipedia.org/wiki/philosphy\",\n",
    "#              \"https://en.wikipedia.org/wiki/usa\",\n",
    "#              \"https://en.wikipedia.org/wiki/germany\",\n",
    "#              \"https://en.wikipedia.org/wiki/english\",\n",
    "#              \"https://en.wikipedia.org/wiki/harry_potter\",\n",
    "#              \"https://en.wikipedia.org/wiki/james_bond\",\n",
    "#              \"https://en.wikipedia.org/wiki/food\",\n",
    "#              \"https://en.wikipedia.org/wiki/banana\",\n",
    "#              \"https://en.wikipedia.org/wiki/apple\",\n",
    "#              \"https://en.wikipedia.org/wiki/language\",\n",
    "#              \"https://en.wikipedia.org/wiki/ber\",\n",
    "#              \"https://en.wikipedia.org/wiki/english_wikipedia\",\n",
    "#              \"https://en.wikipedia.org/wiki/Online_encyclopedia\",\n",
    "#              \"https://en.wikipedia.org/wiki/British_English\",\n",
    "#              \"https://en.wikipedia.org/wiki/youtube\",\n",
    "#              \"https://en.wikipedia.org/wiki/facebook\",\n",
    "#              \"https://en.wikipedia.org/wiki/instagram\",\n",
    "#              \"https://en.wikipedia.org/wiki/tesla\",\n",
    "#              \"https://en.wikipedia.org/wiki/new_york\",\n",
    "#              \"https://en.wikipedia.org/wiki/Online_video_platform\",\n",
    "#              \"https://en.wikipedia.org/wiki/Entertainment\",\n",
    "#              \"https://en.wikipedia.org/wiki/Most_common_words_in_English\",\n",
    "#              \"https://en.wikipedia.org/wiki/Oxford_English_Corpus\",\n",
    "#              \"https://en.wikipedia.org/wiki/book\",\n",
    "#              \"https://en.wikipedia.org/wiki/elon_musk\",\n",
    "#              \"https://en.wikipedia.org/wiki/copyright\",\n",
    "#              \"https://en.wikipedia.org/wiki/drawing\",\n",
    "#              \"https://en.wikipedia.org/wiki/sketching\",\n",
    "#              \"https://en.wikipedia.org/wiki/dollar\",\n",
    "#              \"https://en.wikipedia.org/wiki/euro\",\n",
    "#              \"https://en.wikipedia.org/wiki/!\",\n",
    "#              \"https://en.wikipedia.org/wiki/?\",\n",
    "#              \"https://en.wikipedia.org/wiki/dot\",\n",
    "#              \"https://en.wikipedia.org/wiki/beer\",\n",
    "#              \"https://en.wikipedia.org/wiki/architecture\",\n",
    "#              \"https://en.wikipedia.org/wiki/text\",\n",
    "#              \"https://en.wikipedia.org/wiki/money\",\n",
    "#              \"https://en.wikipedia.org/wiki/paris\",\n",
    "#              \"https://en.wikipedia.org/wiki/hotel\",\n",
    "#              \"https://en.wikipedia.org/wiki/motel\",\n",
    "#              \"https://en.wikipedia.org/wiki/city\",\n",
    "#              \"https://en.wikipedia.org/wiki/internet\",\n",
    "#              \"https://en.wikipedia.org/wiki/influencer\",\n",
    "#              \"https://en.wikipedia.org/wiki/youth\",\n",
    "#              \"https://en.wikipedia.org/wiki/Languages_of_the_United_States\",\n",
    "#              \"https://en.wikipedia.org/wiki/unity\",\n",
    "#              \"https://en.wikipedia.org/wiki/bible\",\n",
    "#              \"https://en.wikipedia.org/wiki/church\",\n",
    "#              \"https://en.wikipedia.org/wiki/marvel\",\n",
    "#              \"https://en.wikipedia.org/wiki/movie\",\n",
    "#              \"https://en.wikipedia.org/wiki/superman\",\n",
    "#              \"https://en.wikipedia.org/wiki/batman\",\n",
    "#              \"https://en.wikipedia.org/wiki/fortnite\",\n",
    "#              \"https://en.wikipedia.org/wiki/slang\",\n",
    "#              \"https://en.wikipedia.org/wiki/drink\",\n",
    "#              \"https://en.wikipedia.org/wiki/queen\",\n",
    "#              \"https://en.wikipedia.org/wiki/king\",\n",
    "#              \"https://en.wikipedia.org/wiki/great_britian\",\n",
    "#              \"https://en.wikipedia.org/wiki/london\",\n",
    "#              \"https://en.wikipedia.org/wiki/atlantic_ocean\",\n",
    "#              \"https://en.wikipedia.org/wiki/ocean\",\n",
    "#              \"https://en.wikipedia.org/wiki/English_people\",\n",
    "#              \"https://en.wikipedia.org/wiki/football\",\n",
    "#              \"https://en.wikipedia.org/wiki/basketball\",\n",
    "#              \"https://en.wikipedia.org/wiki/australia\",\n",
    "#              \"https://en.wikipedia.org/wiki/england\",\n",
    "#              \"https://en.wikipedia.org/wiki/wales\",\n",
    "#              \"https://en.wikipedia.org/wiki/canada\",\n",
    "#              \"https://en.wikipedia.org/wiki/star_wars\",\n",
    "#              ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.gutenberg.org/cache/epub/50/pg50.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/51/pg51.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/52/pg52.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/53/pg53.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/54/pg54.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/55/pg55.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/56/pg56.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/57/pg57.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/58/pg58.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/59/pg59.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/60/pg60.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/61/pg61.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/62/pg62.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/63/pg63.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/64/pg64.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/65/pg65.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/66/pg66.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/67/pg67.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/68/pg68.txt',\n",
       " 'https://www.gutenberg.org/cache/epub/69/pg69.txt']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  df = pd.read_csv(\"word_frequency.txt\")\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "  if row[\"counts\"] == 1:\n",
    "      df.drop(index, inplace=True)\n",
    "      continue\n",
    "  if any(x in str(row[\"words\"]) for x in DIGITS):\n",
    "      df.drop(index, inplace=True)\n",
    "      continue \n",
    "\n",
    "os.chdir(\"D:/Users/flopp/Documents/VSCode/Python/NLP\")\n",
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  os.remove(\"word_frequency.txt\")\n",
    "df.to_csv(\"word_frequency.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gutenberg.org/cache/epub/50/pg50.txt\n",
      "https://www.gutenberg.org/cache/epub/51/pg51.txt\n",
      "https://www.gutenberg.org/cache/epub/52/pg52.txt\n",
      "https://www.gutenberg.org/cache/epub/53/pg53.txt\n",
      "https://www.gutenberg.org/cache/epub/54/pg54.txt\n",
      "https://www.gutenberg.org/cache/epub/55/pg55.txt\n",
      "https://www.gutenberg.org/cache/epub/56/pg56.txt\n",
      "https://www.gutenberg.org/cache/epub/57/pg57.txt\n",
      "https://www.gutenberg.org/cache/epub/58/pg58.txt\n",
      "https://www.gutenberg.org/cache/epub/59/pg59.txt\n",
      "https://www.gutenberg.org/cache/epub/60/pg60.txt\n",
      "https://www.gutenberg.org/cache/epub/61/pg61.txt\n",
      "https://www.gutenberg.org/cache/epub/62/pg62.txt\n",
      "https://www.gutenberg.org/cache/epub/63/pg63.txt\n",
      "https://www.gutenberg.org/cache/epub/64/pg64.txt\n",
      "https://www.gutenberg.org/cache/epub/65/pg65.txt\n",
      "https://www.gutenberg.org/cache/epub/66/pg66.txt\n",
      "https://www.gutenberg.org/cache/epub/67/pg67.txt\n",
      "https://www.gutenberg.org/cache/epub/68/pg68.txt\n",
      "https://www.gutenberg.org/cache/epub/69/pg69.txt\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:/Users/flopp/Documents/VSCode/Python/NLP\")\n",
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  df = pd.read_csv(\"word_frequency.txt\")\n",
    "  words = df[\"words\"].values.tolist()\n",
    "  counts = df[\"counts\"].values.tolist()\n",
    "else:\n",
    "  words = []\n",
    "  counts = []\n",
    "\n",
    "for url in urls:\n",
    "  text = get_all_text(url)\n",
    "  print(url)\n",
    "  words, counts = add_plain_text_to_counts(text, words, counts)\n",
    "  \n",
    "df = create_df(words, counts)\n",
    "df = df.sort_values(by=\"counts\", ascending=False)\n",
    "\n",
    "os.chdir(\"D:/Users/flopp/Documents/VSCode/Python/NLP\")\n",
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  os.remove(\"word_frequency.txt\")\n",
    "df.to_csv(\"word_frequency.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.gutenberg.org/cache/epub/50/pg50.txt\n",
      "https://www.gutenberg.org/cache/epub/51/pg51.txt\n",
      "https://www.gutenberg.org/cache/epub/52/pg52.txt\n",
      "https://www.gutenberg.org/cache/epub/53/pg53.txt\n",
      "https://www.gutenberg.org/cache/epub/54/pg54.txt\n",
      "https://www.gutenberg.org/cache/epub/55/pg55.txt\n",
      "https://www.gutenberg.org/cache/epub/56/pg56.txt\n",
      "https://www.gutenberg.org/cache/epub/57/pg57.txt\n",
      "https://www.gutenberg.org/cache/epub/58/pg58.txt\n",
      "https://www.gutenberg.org/cache/epub/59/pg59.txt\n",
      "https://www.gutenberg.org/cache/epub/60/pg60.txt\n",
      "https://www.gutenberg.org/cache/epub/61/pg61.txt\n",
      "https://www.gutenberg.org/cache/epub/62/pg62.txt\n",
      "https://www.gutenberg.org/cache/epub/63/pg63.txt\n",
      "https://www.gutenberg.org/cache/epub/64/pg64.txt\n",
      "https://www.gutenberg.org/cache/epub/65/pg65.txt\n",
      "https://www.gutenberg.org/cache/epub/66/pg66.txt\n",
      "https://www.gutenberg.org/cache/epub/67/pg67.txt\n",
      "https://www.gutenberg.org/cache/epub/68/pg68.txt\n",
      "https://www.gutenberg.org/cache/epub/69/pg69.txt\n",
      "https://www.gutenberg.org/cache/epub/70/pg70.txt\n",
      "https://www.gutenberg.org/cache/epub/71/pg71.txt\n",
      "https://www.gutenberg.org/cache/epub/72/pg72.txt\n",
      "https://www.gutenberg.org/cache/epub/73/pg73.txt\n",
      "https://www.gutenberg.org/cache/epub/74/pg74.txt\n",
      "https://www.gutenberg.org/cache/epub/75/pg75.txt\n",
      "https://www.gutenberg.org/cache/epub/76/pg76.txt\n",
      "https://www.gutenberg.org/cache/epub/77/pg77.txt\n",
      "https://www.gutenberg.org/cache/epub/78/pg78.txt\n",
      "https://www.gutenberg.org/cache/epub/79/pg79.txt\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"D:/Users/flopp/Documents/VSCode/Python/NLP\")\n",
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  df = pd.read_csv(\"word_frequency.txt\")\n",
    "  words = df[\"words\"].values.tolist()\n",
    "  counts = df[\"counts\"].values.tolist()\n",
    "else:\n",
    "  words = []\n",
    "  counts = []\n",
    "\n",
    "for url in urls:\n",
    "  text = get_all_text(url)\n",
    "  print(url)\n",
    "  words, counts = add_plain_text_to_counts(text, words, counts)\n",
    "  \n",
    "df = create_df(words, counts)\n",
    "df = df.sort_values(by=\"counts\", ascending=False)\n",
    "\n",
    "os.chdir(\"D:/Users/flopp/Documents/VSCode/Python/NLP\")\n",
    "if os.path.exists(\"word_frequency.txt\"):\n",
    "  os.remove(\"word_frequency.txt\")\n",
    "df.to_csv(\"word_frequency.txt\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b1d25132934853969b328081db8fe8c96150f84bc061a3b969fed288050c01a8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
